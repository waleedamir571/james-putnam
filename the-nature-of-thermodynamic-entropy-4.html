<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog Post</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="public/css/style-blog.css">


</head>

<body>
    <div class="text-center">
        <br><br>
        <img class="w-25" src="assets/logo.png" alt="">
        <br><br>
    </div>
    <div class="container1">
        <img class="w-100" src="assets/3rd.png" alt="">
    </div>
    <div class="container">

        <div class="">

          
        </div>
        <p class="blog-meta1">Independent Researcher

        </p>

        <br>
        <p class="blog-meta">Keywords

        </p>

        <p class="blog-content">
            Thermodynamic Entropy; Boltzmann‚Äôs Constant; Frequency.


        </p>
        <br>
        <p class="blog-meta">Introduction

        </p>

        <p class="blog-content">
            Physics properties are defined by equations. Clausius correctly defined thermodynamic entropy by an equation
            that is simple. Yet, it does not have an explanation for what it is physically. Entropy, temperature,
            Boltzmann‚Äôs
            constant, and Planck‚Äôs constant will each have physical explanations.



        </p>

        <p class="blog-content">
            Thermodynamic properties are properties such as pressure, temperature, and volume for which we make
            macroscopic measurements that pertain to measuring internal energy. The measurement of these properties
            must be done on a medium that is in equilibrium. Temperature is commonly explained as a property that
            demonstrates when two systems are in thermal equilibrium. When the systems are touching with no barrier,
            no measurable exchanges of heat occur between the systems.

            <br><br>
            When external forces act on a system, or when the system exerts a force that acts on its surroundings, then
            the
            forces must act quasi-statically. This means forces must vary so slowly that any thermodynamic imbalance is
            infinitesimally small. In other words, the system is always infinitesimally near a state of true
            equilibrium. If a
            property such as temperature changes, it must occur so slowly that there is no more than an infinitesimal
            temperature variation between any two points within the system.
            <br><br>
            In the work that follows, all parts of a system are in states of equilibrium with one another. All changes
            that
            occur between systems or parts of systems occur sufficiently slow that each part of all systems remain
            infinitesimally close to equilibrium.

            <br>
        <p class="blog-meta">Definition of Thermodynamic Entropy


        </p>
        <p class="blog-content">
            Thermodynamic Entropy is defined by an equation that establishes a direct relationship between the heat
            entering the engine at a constant temperature and an increase in entropy. The equation is:
        </p>
        <br>
        <div class="text-center blog-content">
            ŒîùëÜ =
            ŒîùëÑ

        </div>
        <p class="blog-content">
            Where ŒîS is a change in entropy, and ŒîQ is the corresponding change in heat, i.e., energy in transit, into
            or out
            of a system, and T is the temperature of the system in degrees Kelvin. By convention heat entering the gas
            is
            positive. Heat leaving the gas is negative. The equation that defines thermodynamic entropy is based upon a
            Carnot engine. The engine operates in a four-part cycle.
            <br><br>
            a. There is a steady source of heat and a steady heat sink. The heat source is at temperature Thigh, the
            heat
            sink is at temperature T<sub>low.</sub> The Carnot engine operates cyclically between these two
            temperatures. The
            engine will absorb heat from source Thigh and reject heat to source T<sub>low.</sub> For this example, the
            working
            substance is an ideal gas.
            <br><br>
            b. The cycle begins with the engine in unrestricted contact with the heat source Thigh. This is the point
            from which the cycle starts. The gas volume expands pushing a piston against an outside resistance.
            This action occurs quasi-statically, i.e., so slowly that the temperature of the ideal gas remains constant
            at T<sub>high.</sub>
            <br><br>
            c. The engine is removed from contact with Thigh. The heated gas continues to expand adiabatically, i.e.,
            no heat enters or leaves the engine, until its temperature falls, due to expansion, to that of the heat sink
            T<sub>low.</sub>
            <br><br>
            d. The engine is put in contact with the heat sink Tlow. The gas is compressed while remaining at
            temperature Tlow. This is accomplished by quasi-statically absorbing heat into the heat sink which
            remains at temperature T <sub>low.</sub>
            <br><br>
            e. The engine is separated from the heat sink while the returning piston adiabatically continues to
            compress the ideal gas causing its temperature to rise to Thigh. This ends the four-part cycle. The cycle
            repeats itself. This type of engine is a reversible Carnot engine.
            <br><br>
            It is known for the reversible Carnot engine that:

        </p>
        <br>
        <div class="text-center blog-content">
            $$ \frac{\Delta Q_h}{T_h} = \frac{\Delta Q_l}{T} $$
        </div>
        <p class="blog-content">
            The temperatures \(T_h\) and \(T_l\) may vary, but the equality of this relationship remains true. This
            relationship is
            the basis of the definition of thermodynamic entropy. The equation defining thermodynamic entropy is the
            first
            equation, but the second equation is used more often because theoretical physics changed entropy into
            something different from what Clausius defined. The major difference between the two is that Clausius‚Äôs
            entropy is independent of temperature and the invented entropy is dependent upon temperature.
        </p>
        <br>
        <div class="text-center blog-content">
            $$ S = \frac{Q}{T} \quad \text{or} \quad \Delta S = \frac{\Delta Q}{T} $$
        </div>
        <p class="blog-content">
            For Clausius‚Äô entropy of a reversible Carnot engine, these equations are equivalent. There is no change in
            the rate of increase or decrease of entropy. Entropy \(S\) increases at a constant rate. Heat \(Q\)
            increases at a
            constant rate. This condition is due to the temperature \(T\) remaining constant.
            <br><br>
            By convention, the entropy of the gas will increase when expanding while in contact with \(T_{high}\)
            and will decrease when compressing while in contact with \(T_{low}\). Therefore, the increase in entropy is
            given by:
        </p>
        <br>
        <div class="text-center blog-content">
            $$ \Delta S_i = \frac{\Delta Q_h}{T_h} $$
        </div>
        <br>
        <p class="blog-content">
            And the decrease in entropy is given by:
        </p>
        <div class="text-center blog-content">
            $$ -\Delta S_d = \frac{\Delta Q_l}{T_l} $$
        </div>
        <br>
        <p class="blog-content">
            For a reversible Carnot engine, their sum is:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S_i - \Delta S_d = 0 $$
        </div>
        <br>
        <p class="blog-content">
            There is no net change in entropy for the reversible Carnot engine, i.e., the cycle of the engine is brought
            back to its initial condition with no change in entropy.
            <br><br>
            Clausius‚Äôs definition of entropy shows how thermodynamic entropy is calculated but does not make clear what
            entropy is. Neither Clausius nor today‚Äôs physicists could explain what thermodynamic entropy is. The units
            of entropy are joules per degree Kelvin.
            <br><br>
            It is temperature that masks the identity of entropy. Temperature is an indefinable property in theoretical
            physics. It is accepted as a fundamentally unique property along with distance, time, mass, and electric
            charge.
            If the physical action that is temperature was identified, then entropy would be explainable.
            <br><br>
            What is entropy? It is something whose nature should be easily seen because its derivation is part of the
            operation of the simple, fundamental Carnot engine. The answer can be found in the operation of the Carnot
            engine. The Carnot engine is the most efficient engine, theoretically speaking. Its efficiency is
            independent of the nature of the working medium, in this case, a simple gas. Efficiency depends only upon
            the values of the
            high and low temperatures in degrees Kelvin. Degrees Kelvin must be used because the Kelvin temperature
            scale is
            derived based upon the Carnot cycle.
            <br><br>
            The engine‚Äôs equation of efficiency and the definition of the Kelvin temperature scale are the basis for the
            derivation of the equation:
        </p>
        <br>
        <div class="text-center blog-content">
            $$ f_{\xi} = \frac{q_1 q_2}{4 \pi \varepsilon r^2} $$
        </div>

        <p class="blog-content">
            Something very important happens during this derivation that establishes a definite rate of operation of the
            Carnot cycle. The engine is defined as operating quasi-statically. The general requirement for this to be
            true is
            that the engine should operate so slowly that the temperature of the working medium should always measure
            the same at any point within the medium. This is a condition that must be met for a system to be described
            as
            operating infinitesimally close to equilibrium.
            <br>
            There are several rates of operation that will satisfy this condition; however, there is one specific rate,
            above
            which, the equilibrium will be lost. Any slower rate will work fine. The question is: What is this rate of
            operation
            that separates equilibrium from disequilibrium? It is important to know this because this is the rate that
            becomes fixed into the derivation of the Carnot engine. This occurs because the engine is defined such that
            the
            ratio of its heat absorbed to its heat rejected equals the ratio of the temperatures of the high and low
            heat
            sources:

        </p>
        <div class="text-center blog-content">
            $$ \frac{Q_h}{Q_l} = T_h $$
        </div>
        <p class="blog-content">
            This special rate of operation could be identified if the physical meaning of temperature was made clear. In
            this
            new theory, temperature is identified and defined as the rate of exchange of energy between molecules.
            Temperature is not quantitatively the same as that rate because temperature is assigned the units of degrees
            and its scale is arbitrarily fitted to the freezing and boiling points of water. The temperature difference
            between
            these points on the Kelvin scale is set at 100 degrees. For this reason, the quantitative measurement of
            temperature is not the same as the quantitative measurement of exchange of energy between molecules.
            However, this discrepancy can be moderated with the introduction of a constant of proportionality:
        </p>
        <div class="text-center blog-content">
            $$ \frac{dQ}{dt} = kT $$
        </div>
        <p class="blog-content">
            $$ dQ = kT dt T $$
        </p>
        <div class="text-center blog-content">
            This equation indicates that the differential of entropy is:
        </div>
        <div class="text-center blog-content">
            $$ dS = kT dt $$
        </div>
        <p class="blog-content">
            Both dS and dt are variables. It is necessary to determine a value for the constant kT. This value may be
            contained in the ideal gas law:
        </p>
        <div class="text-center blog-content">
            $$ E = n \frac{3}{2} k $$
        </div>
        <p class="blog-content">
            Where k is Boltzmann‚Äôs constant. If I let n=1, then the equation gives the kinetic energy of a single
            molecule. In
            this case E becomes ŒîE an incremental value of energy. Substituting:
        </p>
        <div class="text-center blog-content">
            $$ \Delta E = \frac{3}{2} k $$
        </div>
        <p class="blog-content">
            This suggests that for an ideal gas molecule:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = \frac{3}{2} k $$
        </div>
        <p class="blog-content">
            In other words, the entropy of a single ideal gas molecule is constant. The condition under which this is
            true is
            when the gas molecules act like billiard balls and their pressure is very close to zero. Near zero pressure
            for
            any practical temperature requires that the gas molecules be low in number and widely dispersed.
            <br><br>
            I interpret this to mean, under these conditions, that the thermodynamic measurement of temperature and
            kinetic energy approach single molecule status. Normally, thermodynamic properties do not apply to small
            numbers of molecules. However, sometimes it is instructive to establish a link between individual molecules
            and thermodynamic properties, as is done in the development of the kinetic theory of gases. The case at hand
            is an inherent part of the kinetic theory of gases. The ideal gas law written for a single gas molecule
            gives reason
            to consider that for a single molecule:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = \frac{3}{2} $$
        </div>
        <br>
        <p class="blog-content">
            Substituting for Boltzmann‚Äôs constant:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = \frac{3}{2} (1.38 \times 10^{-23} \frac{J}{K}) = 2.07 \times 10^{-23} J $$
        </div>
        <br>
        <p class="blog-content">
            I have defined Entropy as:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = kT \Delta $$
        </div>
        <br>
        <p class="blog-content">
            Therefore, I write:
        </p>
        <div class="text-center blog-content">
            $$ kT \Delta t = 2.07 \times 10^{-23} J $$
        </div>
        <br>
        <p class="blog-content">
            If I could establish a value for Œît, then I could calculate kT. Since this calculation is assumed to apply
            to a single
            gas molecule and is a constant value, I assume that in this special case, t is a fundamental increment of
            time.
            In this theory, there is one fundamental increment of time. It is:
        </p>
        <div class="text-center blog-content">
            $$ \Delta t_c = 1.602 \times 10^{-19} $$
        </div>
        <br>
        <p class="blog-content">
            Substituting this value and solving for kT:
        </p>
        <div class="text-center blog-content">
            $$ kT = \frac{2.07 \times 10^{-23} J}{K} {1.602 \times 10^{-19} s} = 1.292 \times 10^{-4} \frac{J}{s} $$
        </div>
        <br>
        <p class="blog-content">
            Substituting the units for each quantity as determined by this new theory:
        </p>
        <div class="text-center blog-content">
            $$ kT = 1.292 \times 10^{-4} $$
        </div>
        <br>
        <p class="blog-content">
            The value kT is a unit free constant of proportionality. It also follows that Boltzmann‚Äôs constant is
            defined as:
        </p>
        <div class="text-center blog-content">
            $$ k = \frac{2}{3} kT \Delta t $$
        </div>
        <br>
        <p class="blog-content">
            For the ideal gas equation, the entropy of each molecule is a constant:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = kT \Delta t $$
        </div>
        <br>
        <p class="blog-content">
            However, thermodynamic entropy is defined as an aggregate macroscopic function. I have a value for the
            constant kT, but the increment of time in the macroscopic function is not a constant. There are a great
            number
            of molecules involved and their interactions overlap and add together. It is a variable. I expand the
            meaning of
            entropy into its more general form and substitute kT into the general thermodynamic definition of entropy
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = kT \Delta $$
        </div>
        <br>
        <p class="blog-content">
            The Œît in this equation is not the same as the Œîtc in the equation for a single molecule. In the macroscopic
            version, it is the time required for a quantity of energy, in the form of heat, to be transferred at the
            rate
            represented by the temperature in degrees Kelvin. Substituting this equation for entropy into the general
            energy equation:
        </p>
        <div class="text-center blog-content">
            $$ \Delta E = \Delta S T = kT \Delta t $$
        </div>
        <br>
        <p class="blog-content">
            Recognizing that the increment of energy represents an increment of heat entering or leaving the engine, and
            solving for ŒîS:
        </p>
        <div class="text-center blog-content">
            $$ \Delta S = \frac{\Delta E}{T} = \frac{\Delta Q}{T} = kT \Delta t $$
        </div>
        <br>
        <p class="blog-content">
            Solving for Œît:
        </p>
        <div class="text-center blog-content">
            $$ \Delta t = \frac{\Delta S}{kT} = \frac{\Delta Q}{kT} $$
        </div>

        <br>
        <p class="blog-content">
            This function of Œît is what would have become defined as the function of entropy if temperature had been
            defined directly as the rate of transfer of energy between molecules. The arbitrary definition of
            temperature
            made it necessary for the definition of entropy to include the proportionality constant kT. Writing an
            equation
            to show this:




        </p>
        <div class="text-center blog-content">
            \( \frac{\Delta Q}{k T T} = \frac{\Delta Q}{\Delta Q} \Delta \)
        </div>
        <br>
        <p class="blog-content">
            In particular:
        </p>
        <div class="text-center blog-content">
            \( \frac{\Delta Q_h}{k T T_h} = \frac{\Delta Q_h}{\Delta Q_h} \frac{\Delta t}{\Delta t} \)
        </div>
        <br>
        <p class="blog-content">
            For a Carnot engine:
        </p>
        <div class="text-center blog-content">
            \( \frac{\Delta Q_h}{k T T_h} = \frac{\Delta Q_l}{k T T} \)
        </div>
        <br>
        <p class="blog-content">
            Therefore:
        </p>
        <div class="text-center blog-content">
            \( \frac{\Delta Q_h}{\Delta Q_h} \frac{\Delta t}{\Delta t} = \frac{\Delta Q_l}{\Delta Q_l} \Delta \)
        </div>
        <br>
        <p class="blog-content">
            The net change in entropy is:
        </p>
        <div class="text-center blog-content">
            \( \Delta S = \frac{Q_z}{T_{low}} - \frac{Q_z}{T_{high}} \)
        </div>
        <br>
        <p class="blog-content">
            In this theory, Boltzmann‚Äôs constant has acquired the definition:
        </p>
        <div class="text-center blog-content">
            \( k = \frac{2}{3} k T \Delta t c \)
        </div>
        <br>
        <p class="blog-content">
            There is a relationship between Planck‚Äôs constant \( h \) and Boltzmann‚Äôs constant \( k \):
        </p>
        <div class="text-center blog-content">
            \( h = k \Delta x \)
        </div>
        <br>
        <p class="blog-content">
            Substituting for \( k \) and rearranging terms:
        </p>
        <div class="text-center blog-content">
            \( h = k T \left( \frac{2}{3} \Delta x c \right) \Delta t \)
        </div>
        <br>
        <p class="blog-content">
            Using the equation:
        </p>
        <div class="text-center blog-content">
            \( \Delta E = \Delta S \)
        </div>
        <br>
        <p class="blog-content">
            Since:
        </p>
        <div class="text-center blog-content">
            \( T = \frac{2}{3} \Delta x c \)
        </div>
        <br>
        <p class="blog-content">
            Substituting:
        </p>
        <div class="text-center blog-content">
            \( \Delta E = \Delta S \frac{2}{3} \Delta x c \)
        </div>
        <br>
        <p class="blog-content">
            Since:
        </p>
        <div class="text-center blog-content">
            \( \Delta S = k T \Delta t \)
        </div>
        <br>
        <p class="blog-content">
            Substituting:
        </p>
        <div class="text-center blog-content">
            \( \Delta E = k T \Delta t c \frac{2}{3} \Delta x c \)
        </div>
        <br>
        <p class="blog-content">
            Rearranging:
        </p>
        <div class="text-center blog-content">
            \( \Delta E = k T \frac{2}{3} \Delta x c \Delta t c \omega = h \)
        </div>
        <br>
        <p class="blog-content">
            Making the same change for general cases:
        </p>
        <div class="text-center blog-content">
            \( \Delta E = \left( k T \frac{2}{3} \Delta x c \Delta t \right) \)
        </div>
        <br>
        <p class="blog-content">
            Defining an analogy to entropy for frequency:
        </p>
        <div class="text-center blog-content">
            \( \Delta S_p = \left( k T \frac{2}{3} \Delta x c \Delta t \right) \)
        </div>
        <br>
        <p class="blog-content">
            Substituting:
        </p>
        <div class="text-center blog-content">
            \( \Delta E = \Delta S_p \)
        </div>
        <br>
        <p class="blog-content">
            Now I give a detailed general definition for Planck's constant:
        </p>
        <div class="text-center blog-content">
            \( \frac{d\xi}{dx} = \frac{dB}{d} \)
        </div>
        <br>
        <p class="blog-content">
            The potential energy of the hydrogen electron in its first energy level is:
        </p>
        <div class="text-center blog-content">
            \( f = q \xi \)
        </div>
        <br>
        <p class="blog-content">
            Where:
        </p>
        <div class="text-center blog-content">
            \( \omega_{eH1} = \frac{\nu_{eH1}}{\lambda_{eH1}} = \frac{\nu c \alpha}{2 \pi \Delta x} \)
        </div>
        <br>
        <p class="blog-content">
            Substituting for the speed of light:
        </p>
        <div class="text-center blog-content">
            \( \omega_{eH1} = \left( \frac{\Delta x c}{\Delta t c} \right) \alpha \frac{1}{2 \pi \Delta x c} =
            \frac{\alpha}{2 \pi \Delta t c} = \frac{1}{2 \pi (137) \Delta t} \)
        </div>

        <br>
        <p class="blog-content">
            The denominator on the right side is the period of the frequency. Therefore:

        </p>

        <div class="text-center blog-content">
            \(\Delta E_{eH1} = \frac{h}{2\pi\alpha^{-1} \Delta}\)
        </div>
        <br>
        <p class="blog-content">
            Also, the potential energy for a circular orbit can be expressed as:
        </p>
        <div class="text-center blog-content">
            \(\Delta E_{eH1} = f_{eH1} \Delta x\)
        </div>
        <br>
        <p class="blog-content">
            Therefore:
        </p>
        <div class="text-center blog-content">
            \(f_{eH1} \Delta x_c = \frac{h}{2\pi\alpha^{-1} \Delta t}\)
        </div>
        <br>
        <p class="blog-content">
            Solving for Planck‚Äôs constant:
        </p>
        <div class="text-center blog-content">
            \(h = f_{eH1} \Delta x_c \Delta t_c 2\pi\alpha^{-1}\)
        </div>
        <p class="blog-content">
            This result defines Planck‚Äôs constant in terms of properties of the hydrogen atom.
        </p>
        <p class="blog-meta">Defining Temperature</p>
        <p class="blog-content">
            I have defined temperature as:
        </p>
        <div class="text-center blog-content">
            \(T = \frac{k_T \Delta E}{\Delta t}\)
        </div>
        <br>
        <p class="blog-content">
            I have also derived:
        </p>
        <div class="text-center blog-content">
            \(h = k_T \left( \frac{2}{3} \Delta x_c \right) \Delta t\)
        </div>
        <br>
        <p class="blog-content">
            Solving for \(k_T\):
        </p>
        <div class="text-center blog-content">
            \(k_T = \frac{h}{\left( \frac{2}{3} \Delta x_c \right) \Delta t}\)
        </div>
        <br>
        <p class="blog-content">
            Since:
        </p>
        <div class="text-center blog-content">
            \(h = f_{eH1} \Delta x_c \Delta t_c 2\pi\alpha^{-1}\)
        </div>
        <br>
        <p class="blog-content">
            Then:
        </p>
        <div class="text-center blog-content">
            \(k_T = \frac{f_{eH1} \Delta x_c \Delta t_c 2\pi\alpha^{-1} \left( \frac{2}{3} \Delta x_c \right) \Delta
            t_c}{3} = 3 f_{eH1} \pi \alpha^{-1}\)
        </div>
        <br>
        <p class="blog-meta">Defining Boltzmann‚Äôs Constant</p>
        <p class="blog-content">
            I have established a relationship between Planck‚Äôs constant and Boltzmann‚Äôs constant in the form of:
        </p>
        <div class="text-center blog-content">
            \(k_B = \frac{h}{\Delta x}\)
        </div>
        <br>
        <p class="blog-content">
            Substituting for Planck‚Äôs constant:
        </p>
        <div class="text-center blog-content">
            \(k_B = \frac{k_T \left( \frac{2}{3} \Delta x_c \right) \Delta t_c}{\Delta x_c} = k_T \frac{2}{3} \Delta t\)
        </div>
        <p class="blog-content">
            Substituting for \(k_T\):
        </p>
        <div class="text-center blog-content">
            \(k_B = \frac{3 f_{eH1} 2\pi\alpha^{-1} 2}{3} \Delta t_c = f_{eH1} 2\pi\alpha^{-1} \Delta t_c\)
        </div>
        <br>
        <p class="blog-content">
            Or, in terms of momentum:
        </p>
        <div class="text-center blog-content">
            \(k_B = \Delta P_{eH1} 2\pi\)
        </div>
        <br>
        <p class="blog-content">
            Where:
        </p>
        <div class="text-center blog-content">
            \(\Delta P_{eH1} = f_{eH1} \alpha^{-1} \Delta t_c = f_{eH1} \Delta t_{eH1}\)
        </div>
        <br>
        <p class="blog-meta">Defining Frequency</p>
        <p class="blog-content">
            Defining Frequency
        </p>
        <div class="text-center blog-content">
            \(h = k_B \Delta x\)
        </div>
        <br>
        <p class="blog-content">
            Substituting for \(k_B\):
        </p>
        <div class="text-center blog-content">
            \(h = \Delta P_{eH1} 2\pi \Delta x_c = \Delta P_{eH1} \lambda_{eH1}\)
        </div>
        <br>
        <p class="blog-content">
            Also:
        </p>
        <div class="text-center blog-content">
            \(\Delta E_{eH1} = h\omega = \Delta P_{eH1} \lambda_{eH1} \omega_{eH1} = \Delta P_{eH1} v_{eH1}\)
        </div>
        <br>
        <p class="blog-content">
            And, from an earlier result:
        </p>
        <div class="text-center blog-content">
            \(h = f_{eH1} \Delta x_c \Delta t_c 2\pi\alpha^{-1}\)
        </div>
        <br>
        <p class="blog-content">
            Yielding:
        </p>
        <div class="text-center blog-content">
            \(\Delta E = h\omega = f_{eH1} \Delta x_c \Delta t_c \alpha^{-1} 2\pi\omega = (f_{eH1} \Delta
            x_c)(\alpha^{-1} \Delta t_c)(2\pi\omega)\)
        </div>

        <br>
        <p class="blog-content">
            The first set of parenthesis contains the potential energy of the hydrogen electron in its first energy
            level. The
            second set is the period of time required for the electron to complete one radian. The third set is the
            angular
            velocity of the electron in units of radians per second.
            <br><br>
            This theory‚Äôs definition of Planck‚Äôs constant first changes frequency into radians per second. Then, it
            converts
            radians per second, for the subject frequency, into a measure of the number of radians traveled during the
            period of time required for the hydrogen electron to travel one radian. Finally, the result of the first two
            steps
            is multiplied by the potential energy of the hydrogen electron in its first energy level. In other words,
            Planck‚Äôs
            constant uses fundamental properties of the hydrogen atom as the standard by which to convert frequencies
            into quantities of energy.

        </p>
        <p class="blog-meta">Boltzmann‚Äôs Entropy
        </p>
        <p class="blog-content">
            This theory introduces the idea that a consequence of defining thermodynamic entropy using an ideal gas is
            that, as the pressure approaches zero, the exchanges of energy between molecules theoretically reduce
            to single exchanges. A point is reached where exchanges occur at a rate that can be modeled as one at
            a time without delay between them. That is an equilibrium point where the temperature is close to a constant
            value. Clausius‚Äô thermodynamic entropy applies to that low pressure where the exchanges that occur can
            be ideally represented as each molecule taking its turn, without delay, to pass on average molecular
            kinetic energy. This process can be modeled by considering all the gas molecules lined up in a single file
            and the average molecular kinetic energy of one of them is transferred down the line from molecule to
            molecule until the energy has been transferred to the last molecule. The time required to complete this
            process is ‚Äòinternal‚Äô thermodynamic entropy.

            <br><br>
            Temperature is proportional to the rate of transfer of average molecular kinetic energy between molecules.
            The modified temperature is the rate at which energy is transferred between molecules. The numerator of
            the modified temperature is average molecular kinetic energy. The average kinetic energy of an ideal gas
            depends upon temperature only. It was shown that the average kinetic energy divided by modified
            temperature equals:


        </p>
        <div class="text-center blog-content">
            \[ \frac{1}{2} m v^2 = k_T T \Delta t \]
        </div>
        <br>
        <p class="blog-content">
            In the equation below, Boltzmann‚Äôs constant is defined as the first equal term and by thermodynamics
            as the second equal term:
        </p>
        <div class="text-center blog-content">
            \[ k = \frac{2}{3} k_T \Delta t_c = R \]
        </div>
        <br>
        <p class="blog-content">
            N is Avogadro‚Äôs number, the number of molecules in a mole of gas. R is the universal gas constant. Solving for R:
        </p>
        <div class="text-center blog-content">
            \[ R = \frac{2}{3} N k_T \Delta t \]
        </div>
        <br>
        <p class="blog-content">
            Substituting the appropriate values:
        </p>
        <div class="text-center blog-content">
            \[ R = \frac{2}{3} (6.02 \times 10^{23} \text{ mole}^{-1}) (1.292 \times 10^{-4}) (1.602 \times 10^{-19}s) = 8.31(s \times \text{mole}^{-1}) \]
        </div>
        <br>
        <p class="blog-content">
            For one mole of gas:
        </p>
        <div class="text-center blog-content">
            \[ R = \frac{2}{3} (6.02 \times 10^{23}) (1.292 \times 10^{-4}) (1.602 \times 10^{-19}s) = 8.31 \]
        </div>
        <br>
        <p class="blog-content">
            The universal gas constant R is directly proportional to the total time required for a mole of ideal gas to
            transfer average molecular kinetic energy from molecule to molecule without delay between exchanges until
            the number of molecules in a mole of gas is reached. 
        </p>
        <div class="text-center blog-content">
            \[ \frac{3}{2} \left( \frac{R}{k_T} \right) = N(\Delta t_c) = (6.02 \times 10^{23} \text{ mole}^{-1}) (1.602 \times 10^{-19}s) \]
            \[ = 96,440 s \times \text{mole}^{-1} = 26.8 \text{ hrs} \times \text{mole}^{-1} \]
        </div>
        <br>
        <p class="blog-content">
            Boltzmann‚Äôs constant is the time represented by the universal gas constant R reduced to single molecule status:
        </p>
        <div class="text-center blog-content">
            \[ k = \frac{R}{N} = \frac{8.312}{6.02 \times 10^{23} \text{ mole}^{-1}} = 1.38 \times 10^{-23} \]
        </div>
        <br>
        <p class="blog-content">
            Strictly speaking, the units of degrees should have been included in the two equations above. I took the
            liberty of not showing it for reason of readability.
        </p>
        <div class="text-center blog-content">
            \[ \Delta t_c = \frac{3}{2} \left( \frac{k}{k_T} \right) = 1.602 \times 10^{-19} \]
        </div>
        <br>
        <p class="blog-content">
            The number of possible arrangements for a mole of ideal gas is infinite. Boltzmann‚Äôs entropy requires
            there to be a limited number of possible arrangements.
        </p>
        <div class="text-center blog-content">
            \[ S = k \Omega \]
        </div>
        <br>
        <p class="blog-content">
            Boltzmann‚Äôs entropy is defined as:
        </p>
        <div class="text-center blog-content">
            \[ S = k \log \Omega \]
        </div>
        
        <br>
        <p class="blog-content">
            Therefore, Boltzmann‚Äôs entropy is proportional to the time of a single transfer of ideal gas molecule energy
            times the logarithm of the number of microstates. Boltzmann‚Äôs entropy is not an expression of simulated
            internal thermodynamic entropy. Boltzmann‚Äôs entropy is no longer a direct measure of time. The units of
            seconds carried along by Boltzmann‚Äôs constant have become irrelevant. Boltzmann‚Äôs constant can be set to
            unity without units. Its connection to thermodynamic entropy is already lost.



        </p>

        <br>
        <p class="blog-meta">Conclusion:


        </p>
        <br>
        <p class="blog-content">
            Clausius‚Äôs thermodynamic entropy is the time it takes for heat Q1 to be absorbed into an ideal gas at the
            rate
            of temperature Thigh or for Q2 to be released out of an ideal gas at the rate of temperature Tlow. The time
            it
            takes for a single ideal gas molecule to pass its kinetic energy off to another ideal gas molecule at a
            distance
            equal to the radius of the hydrogen atom is the unit of absolute time derived in the article A Unit of
            Absolute
            Universal Time.
        </p>
        <br>
        <p class="blog-meta">Bibliography

        </p>
        <br>
        <p class="blog-content">
            Sears FW. College Physics, Addison-Wesley (Reading) (1960).
            <br><br>
            Zemansky MW. Heat and Thermodynamics, McGraw-Hill, (Reading) (1943).
            <br><br>
            Fermi E. Thermodynamics, Prentice-Hall, (Reading) (1937).

        </p>



    </div>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</body>

</html>